<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184/284 Final</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184/284: Final Project Proposal</h1>
<h1 align="middle">Point Cloud to Mesh</h1>
<h2 align="middle">Sean Wang, Shu-Ping Chen, I-Lun Tsai, Kevin Xiong</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="TODO">TODO</a></h2>

<br><br>


<!--<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>-->
<!--<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p>-->
<!--<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>-->
<!---->
<!---->
<!--<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>-->
<!--<ul>-->
<!--<li>Your main report page should be called index.html.</li>-->
<!--<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>-->
<!--<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>-->
<!--Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>-->
<!--<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>-->
<!--<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>-->
<!--<li>And again, test your website on the instructional machines early!</li>-->
<!--</ul>-->
<!---->
<!---->
<!--<p>Here is an example of how to include a simple formula:</p>-->
<!--<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>-->
<!--<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>-->

<div>

<h2 align="middle">Introduction</h2>
<p>This proposal provides an overview of a promising technique in computer vision and graphics, which involves reconstructing a colored 3D mesh from point clouds captured using Kinect sensors. The goal is to create a pipeline that can generate texture meshes from Kinect scans of objects or scenes that can be rendered.

</p>
<h2 align="middle">Problem Description</h2>
<p>The objective of this project is to tackle the challenge of creating texture meshes from point clouds obtained through Kinect sensors. This is a significant problem as it plays a vital role in various fields, such as virtual reality, gaming, digital art, and computer-aided design. The process of generating high-quality and accurate 3D models is complex as it requires combining several components such as point cloud processing and mesh reconstruction algorithms.
To overcome this obstacle, we intend to design a comprehensive pipeline that will involve capturing point cloud data through Kinect sensors, extracting relevant information by processing the data, utilizing mesh reconstruction algorithms such as Ball-Pivoting algorithm and Poisson Surface Reconstruction algorithm, and evaluating the quality of the reconstructed meshes using benchmark datasets like the Stanford 3D Scanning Repository. Moreover, our approach will include capturing the real color of the object and projecting it onto the reconstructed mesh.

Our primary goal is to gain a deeper understanding of 3D scanning and reconstruction technologies while also making a significant contribution to the field of computer vision and graphics.


</p>
<br>

<h2 align="middle">Goals and Deliverables</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Project Overview
</h3>
<p> Our project aims to develop a comprehensive pipeline that takes input from Kinect scanning of a scene or an object and generates texture meshes that can be rendered. The pipeline will consist of multiple interconnected parts that work together to achieve the desired outcome.

</p>
<br>

<h3>
  Pipeline Components
</h3>
<p>1. Kinect Input: We will utilize the Kinect sensor to capture point cloud data of the object or scene of interest. The Kinect sensor is capable of capturing depth and RGB information, which will be used as the input for our pipeline.

</p>
<p>2. Point Cloud Processing: Once the point cloud data is obtained from the Kinect sensor, we will process it to extract relevant information. This may involve filtering, noise reduction, and data normalization techniques to prepare the point cloud data for mesh reconstruction.
</p>
<p>3. Mesh Reconstruction: (1 Baseline Plan) We plan to implement an algorithm for mesh reconstruction: the Ball-Pivoting algorithm. The Ball-Pivoting algorithm is a widely used method for reconstructing triangle meshes from point cloud data. (2 Advanced Plan) If the Ball-Pivoting algorithm goes well, we will further implement the Poisson Surface Reconstruction algorithm, which is another surface reconstruction algorithm which is also known for producing smooth and visually appealing meshes.
</p>
<p>4. Mesh Quality Evaluation: To assess the quality of our mesh reconstruction implementation, we will compare the results with those obtained from the Stanford 3D Scanning Repository, which is a widely used benchmark dataset for evaluating 3D scanning and reconstruction methods. This will allow us to measure the accuracy and fidelity of our reconstructed meshes and validate the performance of our pipeline. We will select MOS (Mean Opinion Score) as our metric to determine the performance of our system.
</p>
<p>5. Color the reconstructed mesh: (Advanced Plan) We will capture the real color of the object and project the color onto the reconstructed mesh.
</p>
<br>
<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="image2.png" width="846px" height = "336px" />
      </tr>
  </table>
</div>
<h3>
  Conclusion
</h3>
<p>In summary, our project aims to develop a pipeline that takes Kinect scanning input, processes the point cloud data, and applies mesh reconstruction algorithms to generate texture meshes that can be rendered. By comparing the results with a benchmark dataset, we will be able to evaluate the quality of our implementation and ensure that our pipeline produces accurate and visually appealing meshes. This project has the potential to find applications in fields such as virtual reality, gaming, computer-aided design, and digital art. Overall, our pipeline has the potential to contribute to the advancement of 3D scanning and reconstruction technologies, and we are excited about the prospects of our project. As we progress, we will continue to refine and optimize our pipeline to achieve the best possible results. Through this project, we hope to make a meaningful contribution to the field of computer vision and graphics.
</p>
<br>
</body>
</html>

